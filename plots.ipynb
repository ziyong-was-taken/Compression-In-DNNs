{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"version_X\"\n",
    "\n",
    "# load metrics and merge train and val rows\n",
    "metrics = pd.read_csv(f\"lightning_logs/{version}/metrics.csv\")\n",
    "metrics = metrics.groupby(\"epoch\").first()\n",
    "\n",
    "# fill in missing values for DIB when l=0\n",
    "for v_info in (\"vsuff\", \"vmin\"):\n",
    "    for dataset in (\"train\", \"val\"):\n",
    "        metrics[f\"{v_info}_0_{dataset}\"] = metrics[f\"{v_info}_0_{dataset}\"].ffill()\n",
    "\n",
    "# add generalisation error\n",
    "metrics[\"gen_error\"] = metrics[\"val_loss\"] - metrics[\"train_loss\"]\n",
    "\n",
    "# save cleaned metrics\n",
    "if not os.path.exists(version):\n",
    "    os.mkdir(version) \n",
    "metrics.to_csv(f\"../Overleaf/data/{version}.csv\")\n",
    "display(metrics)\n",
    "\n",
    "# initial legend elements\n",
    "base_handles = [\n",
    "    Line2D([], [], color=\"gray\", linestyle=linestyle) for linestyle in (\"-\", \"--\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(metric):\n",
    "    return [\n",
    "        metrics.filter(regex=f\"{metric}_(layer_)?[0-9]_{dataset}\").columns\n",
    "        if metric != \"acc-loss\"\n",
    "        else metrics.filter(like=f\"{dataset}_\").columns\n",
    "        for dataset in (\"train\", \"val\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def plot_metrics(name, labels, ylabel, xlabel=\"epoch of main network training\", dummy=False):\n",
    "    for i, dataset_cols in enumerate(get_cols(name)):\n",
    "        if dummy:  # dummy plot to iterate colour cycle\n",
    "            plt.plot([])\n",
    "        plt.plot(metrics.index, metrics[dataset_cols], linestyle=[\"-\", \"--\"][i])\n",
    "        plt.gca().set_prop_cycle(None)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.xticks(range(0, metrics.shape[0], 2))\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True, \"major\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.legend(\n",
    "        base_handles + plt.gca().get_lines()[int(dummy) :],\n",
    "        [\"Train\", \"Test\"] + labels,\n",
    "    )\n",
    "    # plt.savefig(f\"{version}/{name}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\"acc-loss\", [\"Accuracy\", \"Loss\"], \"cross-entropy loss & accuracy\", \"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    \"nc\",\n",
    "    [rf\"$l = {layer}$\" for layer in (1, 2, 3)],\n",
    "    r\"$\\operatorname{tr}(Σ_W^l(Σ_B^l)⁺)$\",\n",
    "    \"epoch\",\n",
    "    dummy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalisation Gap vs. Compression Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort metrics by generalisation error for cleaner plots\n",
    "sorted_metrics = metrics.sort_values(by=\"gen_error\")\n",
    "\n",
    "# only plot positive gen. error\n",
    "gen_error = sorted_metrics[\"gen_error\"]\n",
    "pos_mask = gen_error > 0\n",
    "\n",
    "plt.plot([])  # dummy plot to iterate colour cycle\n",
    "for train_col, test_col in zip(*get_cols(\"nc\")):\n",
    "    comp_diff = sorted_metrics[test_col] - sorted_metrics[train_col]\n",
    "    plt.plot(gen_error[pos_mask], comp_diff[pos_mask])\n",
    "plt.legend(plt.gca().get_lines()[1:], [rf\"$l = {layer}$\" for layer in (1, 2, 3)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Between $\\{\\log(\\operatorname{tr}(Σ_W^l(Σ_B^l)⁺))\\}_{l=1}^L$ and $\\{l\\}_{l=1}^L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame where every row is (1,2,…,L)\n",
    "layer_idcs = pd.DataFrame(\n",
    "    np.arange(1, metrics.shape[1] + 1)[np.newaxis, :].repeat(metrics.shape[0], axis=0),\n",
    "    columns=metrics.columns,\n",
    ")\n",
    "\n",
    "for i, dataset_cols in enumerate(get_cols(\"nc\")):\n",
    "    log_metrics = np.log(metrics[dataset_cols])\n",
    "    corrs = log_metrics.corrwith(layer_idcs, axis=1).rename(\n",
    "        f\"{version}_{['train', 'test'][i]}\"\n",
    "    )\n",
    "\n",
    "    # save correlations to csv\n",
    "    if not os.path.exists(\"corrs.csv\"):\n",
    "        corrs.to_csv(\"corrs.csv\")\n",
    "    else:\n",
    "        old_corrs = pd.read_csv(\"corrs.csv\")\n",
    "        old_corrs[f\"{version}_{['train', 'test'][i]}\"] = corrs\n",
    "        old_corrs.to_csv(\"corrs.csv\", index=False)\n",
    "\n",
    "corrs = pd.read_csv(\"corrs.csv\", index_col=0)\n",
    "plt.plot(corrs.index, corrs)\n",
    "plt.xticks(range(0, metrics.shape[0], 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 𝒱-Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sufficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    \"vsuff\",\n",
    "    [rf\"$l = {layer}$\" for layer in (0, 1, 2, 3)],\n",
    "    r\"$\\operatorname{I}_{\\mathcal{V}ˡ}(𝗵ˡ → y)$ in bits\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\n",
    "    \"vmin\",\n",
    "    [rf\"$l = {layer}$\" for layer in (0, 1, 2, 3)],\n",
    "    r\"$\\operatorname{I}_{\\mathcal{V}ˡ}(𝗵ˡ → \\operatorname{Dec}(𝘅, \\mathcal{Y})$ in bits\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate((\"Train\", \"Test\")):\n",
    "    vmin_cols = get_cols(\"vmin\")[i]\n",
    "    vsuff_cols = get_cols(\"vsuff\")[i]\n",
    "    for vmin, vsuff in zip(vmin_cols, vsuff_cols):\n",
    "        x = metrics[vmin]\n",
    "        y = metrics[vsuff]\n",
    "        plt.scatter(x, y, cmap=\"viridis\", c=metrics.index)\n",
    "        plt.plot(x, y, color=\"gray\", linewidth=0.5)\n",
    "    plt.xlabel(r\"$\\operatorname{I}_{\\mathcal{V}ˡ}(𝗵ˡ → \\operatorname{Dec}(𝘅, \\mathcal{Y})$ in bits\")\n",
    "    plt.ylabel(r\"$\\operatorname{I}_{\\mathcal{V}ˡ}(𝗵ˡ → y)$ in bits\")\n",
    "    plt.colorbar(label=\"epoch of main network training\", ticks=range(0, metrics.shape[0], 5))\n",
    "    plt.title(f\"{dataset} Set\")\n",
    "    # plt.savefig(f\"{version}/ip-{dataset.lower()}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Code for generating NC visualisation data\n",
    "%matplotlib ipympl\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(999)\n",
    "\n",
    "\n",
    "def gen_mu(rng=rng, r=0.8):\n",
    "    theta = rng.uniform(0, 2 * np.pi, 3)\n",
    "    phi = rng.uniform(0, np.pi, 3)\n",
    "    return (\n",
    "        r * np.c_[np.sin(phi) * np.cos(theta), np.sin(phi) * np.sin(theta), np.cos(phi)]\n",
    "    )\n",
    "\n",
    "\n",
    "def gen_points(mu, n=5):\n",
    "    return rng.multivariate_normal(mu.flatten(), 0.1 * np.eye(mu.size), n).reshape(\n",
    "        (n, *mu.shape)\n",
    "    )\n",
    "    # return rng.uniform(-1, 1, (n, *mu.shape))\n",
    "\n",
    "\n",
    "mu = gen_mu()\n",
    "points = gen_points(mu)\n",
    "while np.linalg.norm(points, axis=1).max() > 1:\n",
    "    mu = gen_mu()\n",
    "    points = gen_points(mu)\n",
    "mu = points.mean(axis=0)\n",
    "\n",
    "triangle = [[0, 0, 1], [-np.sqrt(3) / 2, 0, -0.5], [np.sqrt(3) / 2, 0, -0.5]]\n",
    "\n",
    "for i in range(3):\n",
    "    np.savetxt(f\"points_{i}.csv\", points[:, i])\n",
    "np.savetxt(\"mu.csv\", mu)\n",
    "np.savetxt(\"simplex.csv\", np.array(triangle))\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "for i in range(3):\n",
    "    ax.scatter(points[:, i, 0], points[:, i, 1], points[:, i, 2])\n",
    "    mu = points[:, i].mean(axis=0)\n",
    "    ax.scatter(*mu, marker=\"x\", color=\"k\")\n",
    "    ax.scatter(*triangle[i], marker=\"+\", color=\"k\") \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
